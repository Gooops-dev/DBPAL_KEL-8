# -*- coding: utf-8 -*-
"""PALING FIXX Project BDPAL Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bTeoXMKfqEN3RASDQ8IQGek0ZTARhIrp
"""

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from pyspark.sql import functions as F
from tabulate import tabulate
from pyspark.sql.functions import col, isnan, when, count

# Membuat Spark Session
spark = SparkSession.builder \
    .appName("AIDS Predict Spark") \
    .getOrCreate()

# menghubungkan collab dengan drive
from google.colab import drive
drive.mount('/content/drive')

# Membaca dataset dengan delimiter ";"
df = spark.read.csv(
    '/content/drive/MyDrive/22.11.5308/Big Data Lanjut/PROJECT UAS/AIDS_Classification.csv',
    header=True,
    inferSchema=True,
    sep=","
)

# Menampilkan 20 baris pertama dengan garis pemisah
df.show(truncate=False)

"""# Exploratory Data Analisis"""

# Mengonversi DataFrame PySpark ke Pandas
pandas_df = df.toPandas()

# Menampilkan tipe data setiap kolom
df.printSchema()

# Menghitung jumlah baris dan kolom
num_rows = df.count()
num_cols = len(df.columns)

print(f"Jumlah Baris: {num_rows}")
print(f"Jumlah Kolom: {num_cols}")

# Menampilkan statistik deskriptif untuk setiap kolom numerik
df.describe().show(truncate=False)

# Menampilkan informasi dataset lebih detail menggunakan tabulate
table_data = []
for col_name in df.columns:
    col_data = df.select(col_name).distinct().rdd.flatMap(lambda x: x).collect()
    table_data.append([col_name, len(col_data), df.select(col_name).dtypes[0][1]])

print(tabulate(table_data, headers=["Column Name", "Number of Unique Values", "Data Type"]))

# Mengubah nilai kosong atau tidak valid menjadi None, lalu mengonversinya ke float
df = df.withColumn("wtkg", when(col("wtkg") == "", None).otherwise(col("wtkg").cast("float")))

# Menghitung jumlah nilai null pada setiap kolom
for col_name in df.columns:
    null_count = df.filter(col(col_name).isNull() | isnan(col(col_name))).count()
    print(f"Jumlah nilai null di kolom '{col_name}': {null_count}")

# Alternatively, for a summary of null values in each column:
df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()

duplicate_rows_df = df.groupBy(df.columns).count().filter('count > 1')
print(f"Jumlah duplikat di seluruh dataset: {duplicate_rows_df.count()}")

# prompt: buatkan visualisasi pie char untuk semua fitur datset
# Assuming 'pandas_df' is your Pandas DataFrame (converted from the PySpark DataFrame)
# Calculate the value counts for each feature
feature_counts = {}
for col in pandas_df.columns:
    feature_counts[col] = pandas_df[col].value_counts()

# Create pie charts for each feature
num_plots = len(feature_counts)
num_cols = 3  # Adjust the number of columns as needed
num_rows = (num_plots + num_cols - 1) // num_cols

fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))
axes = axes.flatten()  # Flatten the axes array for easier iteration

for i, (feature, counts) in enumerate(feature_counts.items()):
    axes[i].pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)
    axes[i].set_title(feature)

# Hide any unused subplots
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# analisis dan visualisasi data univariet
pandas_df = df.toPandas() # convert to pandas DataFrame
pandas_df.hist(bins=50, figsize=(20,15))
plt.show()

plt.figure(figsize=(12, 8))
# Convert the PySpark DataFrame to Pandas before plotting
pandas_df = df.toPandas()
sns.boxplot(data=pandas_df)  # Use the converted Pandas DataFrame
plt.title("Boxplot AIDS", fontsize=16)
plt.xticks(rotation=45, fontsize=12)
plt.ylabel("Values", fontsize=12)
plt.xlabel("Features", fontsize=12)
plt.show()

for col in pandas_df.columns:
  if col != 'infected':
    plt.figure(figsize=(8, 6))  # Adjust figure size as needed
    sns.scatterplot(x='infected', y=col, data=pandas_df)
    plt.title(f'Scatter Plot of {col} vs. Infected')
    plt.xlabel('Infected')
    plt.ylabel(col)
    plt.show()

sns.pairplot(pandas_df, hue='infected')
plt.show()

# prompt: buatkan scter plot untuk datset ini
# Assuming 'pandas_df' is your Pandas DataFrame (converted from the PySpark DataFrame)
# Make sure pandas_df is defined and populated before this code.

plt.figure(figsize=(8, 6))
sns.scatterplot(x='age', y='homo', data=pandas_df)
plt.title('Scatter Plot: Age vs. Homosexual')
plt.xlabel('Age')
plt.ylabel('Homosexual')
plt.show()

plt.figure(figsize=(8, 6))
sns.scatterplot(x='age', y='homo', hue='gender', data=pandas_df)
plt.title('Scatter Plot: Age vs. Homosexual (colored by gender)')
plt.xlabel('Age')
plt.ylabel('Homosexual')
plt.show()

plt.figure(figsize=(8,6))
sns.scatterplot(x='str2', y='z30', data=pandas_df)
plt.title('Scatter Plot: Antiretroviral History vs ZDV in the 30 days')
plt.xlabel('Antiretroviral History')
plt.ylabel('ZDV in the 30 days')
plt.show()

# visualisai data menggunakan heatmap, melihat korelasi antar variable
# Convert PySpark DataFrame to Pandas DataFrame
pandas_df = df.toPandas()

# Calculate correlation matrix using the Pandas DataFrame
corr_matrix = pandas_df.corr()

plt.figure(figsize=(20, 16))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.show()

"""# PRE-PROCESSING

Menghapus Outlier
"""

def remove_outliers_pyspark(df, columns):
    for column in columns:
        # Hitung Q1 dan Q3 menggunakan approxQuantile
        q1, q3 = df.approxQuantile(column, [0.25, 0.75], 0)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        # Filter data untuk menghapus outlier
        df = df.filter((col(column) >= lower_bound) & (col(column) <= upper_bound))
    return df

from pyspark.sql.functions import col, when # Make sure this import is present

# Fungsi untuk menghapus outlier menggunakan IQR
def remove_outliers_pyspark(df, columns):
    for column in columns:
        # Hitung Q1 dan Q3
        q1, q3 = df.approxQuantile(column, [0.25, 0.75], 0)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        # Ganti nilai outlier dengan batas bawah/atas
        # Use pyspark.sql.functions.col explicitly
        df = df.withColumn(
            column,
            when(F.col(column) < lower_bound, lower_bound)  # Using F.col
            .when(F.col(column) > upper_bound, upper_bound)  # Using F.col
            .otherwise(F.col(column))  # Using F.col
        )
    return df

# Mendefinisikan kolom untuk penghapusan outlier
columns_to_clean = ["time", "wtkg", "age", "karnof", "preanti", "cd40", "cd420", "cd80", "cd820"]
df = remove_outliers_pyspark(df, columns_to_clean)

# Mengonversi PySpark DataFrame ke Pandas untuk plotting
df_pd = df.select(columns_to_clean).toPandas()

# Menentukan jumlah kolom dan baris untuk plot
num_cols = len(columns_to_clean[1:])  # Kolom untuk diplot
num_rows = (num_cols + 2) // 3  # Jumlah baris
num_cols_per_row = min(num_cols, 3)  # Kolom per baris maksimum 3

plt.figure(figsize=(10, 10), facecolor='white')
plotnumber = 1

# Membuat boxplot untuk setiap kolom
for column in columns_to_clean[1:]:
    ax = plt.subplot(num_rows, num_cols_per_row, plotnumber)  # Mengatur layout grid
    sns.boxplot(data=df_pd, x=column, ax=ax)
    plt.xlabel(column, fontsize=10)
    plotnumber += 1

plt.tight_layout()  # Mengatur jarak antar subplot
plt.show()

plt.figure(figsize=(12, 8))
# Convert the PySpark DataFrame to Pandas before plotting
pandas_df = df.toPandas()
sns.boxplot(data=pandas_df)  # Use the converted Pandas DataFrame
plt.title("Boxplot AIDS", fontsize=16)
plt.xticks(rotation=45, fontsize=12)
plt.ylabel("Values", fontsize=12)
plt.xlabel("Features", fontsize=12)
plt.show()

"""# Splitting dan Over Sampling"""

from imblearn.over_sampling import SMOTE
from pyspark.ml.feature import VectorAssembler

# Convert PySpark DataFrame to Pandas DataFrame
df_pandas = df.toPandas()
features = ['time', 'trt', 'age', 'wtkg', 'hemo', 'homo', 'drugs', 'karnof',
            'oprior', 'z30', 'preanti', 'race', 'gender', 'str2', 'strat',
            'symptom', 'treat', 'offtrt', 'cd40', 'cd420', 'cd80', 'cd820']

X = df_pandas[features]
y = df_pandas['infected']

import matplotlib.pyplot as plt

print(y.value_counts())


plt.figure(figsize=(8, 6))
plt.hist(y, bins=10)
plt.xlabel('Infected')
plt.ylabel('Frequency')
plt.title('Histogram of Infected')
plt.show()

# Apply SMOTE
smote = SMOTE(sampling_strategy='auto', random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Convert the resampled data back to pandas DataFrame
df_resampled = pd.DataFrame(X_resampled, columns=features)
df_resampled['infected'] = y_resampled

# Convert the resampled DataFrame back to Spark DataFrame
df_spark_resampled = spark.createDataFrame(df_resampled)

# 2. Split data into training and testing sets (80% train, 20% test)
train_df, test_df = df_spark_resampled.randomSplit([0.75, 0.25], seed=42)

# 3. Assemble features into a vector
assembler = VectorAssembler(inputCols=features, outputCol="features")
train_df = assembler.transform(train_df)
test_df = assembler.transform(test_df)

import matplotlib.pyplot as plt

print(y_resampled.value_counts())

plt.figure(figsize=(8, 6))
plt.hist(y_resampled, bins=10)
plt.xlabel('Infected')
plt.ylabel('Frequency')
plt.title('Histogram After Balancing Data')
plt.show()

"""# RF"""

# Import libraries
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.feature import VectorAssembler
from pyspark.sql import SparkSession
import matplotlib.pyplot as plt
import seaborn as sns
from pyspark.sql.functions import col
from sklearn.metrics import classification_report, confusion_matrix, roc_curve

# Initialize Spark session
spark = SparkSession.builder.appName("RandomForestClassifier").getOrCreate()

# 1. Initialize Random Forest Classifier
rf_classifier = RandomForestClassifier(featuresCol="features", labelCol="infected", numTrees=100, seed=42)

# 2. Fit model with training data
rf_model = rf_classifier.fit(train_df)

# 3. Predict using test data
predictions = rf_model.transform(test_df)

# 4. Evaluate Model

# a. Binary Evaluator for AUC
evaluator = BinaryClassificationEvaluator(labelCol="infected", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
auc = evaluator.evaluate(predictions)
print(f"Area Under ROC (AUC): {auc:.2f}")

# b. Confusion Matrix
conf_matrix = predictions.groupBy("infected", "prediction").count().toPandas()
conf_matrix_pivot = conf_matrix.pivot(index="infected", columns="prediction", values="count").fillna(0).astype(int)

# Visualize Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_pivot, annot=True, fmt="d", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# c. Extract Labels and Predictions for Binary Evaluation
def extract_labels_and_predictions(predictions):
    labels_and_preds = predictions.select("infected", "prediction").rdd.map(lambda row: (row["infected"], row["prediction"])).collect()
    y_true, y_pred = zip(*labels_and_preds)
    return y_true, y_pred

y_true, y_pred = extract_labels_and_predictions(predictions)

# d. Classification Report
report = classification_report(y_true, y_pred, target_names=["Negative", "Positive"])
print("\nClassification Report:")
print(report)

# e. ROC Curve
def plot_roc_curve(predictions):
    # Extract probabilities and labels
    probabilities = predictions.select("rawPrediction").rdd.map(lambda row: float(row[0][1])).collect()
    labels = predictions.select("infected").rdd.map(lambda row: row["infected"]).collect()

    # Calculate ROC curve
    fpr, tpr, _ = roc_curve(labels, probabilities)

    # Plot ROC curve
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.2f})')
    plt.plot([0, 1], [0, 1], color='red', linestyle='--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.show()

plot_roc_curve(predictions)

"""#GBT"""

# Import libraries
from pyspark.ml.classification import GBTClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.sql import SparkSession
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, roc_curve

# Initialize Spark session
spark = SparkSession.builder.appName("GBTClassifier").getOrCreate()

# Assuming train_df and test_df are already created and preprocessed as PySpark DataFrames

# 1. Initialize Gradient Boosting Classifier (GBT)
gbt_classifier = GBTClassifier(featuresCol="features", labelCol="infected", maxIter=100, seed=42)

# 2. Fit model with training data
gbt_model = gbt_classifier.fit(train_df)

# 3. Predict using test data
predictions = gbt_model.transform(test_df)

# 4. Evaluate Model

# a. Area Under ROC (AUC)
evaluator_auc = BinaryClassificationEvaluator(labelCol="infected", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
roc_auc = evaluator_auc.evaluate(predictions)
print(f"Area Under ROC (AUC): {roc_auc:.2f}")

# b. Confusion Matrix
conf_matrix = predictions.groupBy("infected", "prediction").count().toPandas()
conf_matrix_pivot = conf_matrix.pivot(index="infected", columns="prediction", values="count").fillna(0).astype(int)

# Visualize Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_pivot, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Negative", "Positive"],
            yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# c. Classification Report
def extract_labels_and_predictions(predictions):
    labels_and_preds = predictions.select("infected", "prediction").rdd.map(lambda row: (row["infected"], row["prediction"])).collect()
    y_true, y_pred = zip(*labels_and_preds)
    return y_true, y_pred

y_true, y_pred = extract_labels_and_predictions(predictions)
report = classification_report(y_true, y_pred, target_names=["Negative", "Positive"])
print("\nClassification Report:")
print(report)

# d. ROC Curve
def plot_roc_curve(predictions):
    # Extract probabilities and labels
    probabilities = predictions.select("probability").rdd.map(lambda row: float(row["probability"][1])).collect()
    labels = predictions.select("infected").rdd.map(lambda row: row["infected"]).collect()

    # Calculate ROC curve
    fpr, tpr, _ = roc_curve(labels, probabilities)

    # Plot ROC curve
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='red', linestyle='--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.show()

plot_roc_curve(predictions)

"""# LOGISTIC REGRESSION"""

# Import libraries
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.sql import SparkSession
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, roc_curve

# Initialize Spark session
spark = SparkSession.builder.appName("LogisticRegressionClassifier").getOrCreate()

# Assuming train_df and test_df are already created and preprocessed as PySpark DataFrames

# 1. Initialize Logistic Regression Classifier
lr_classifier = LogisticRegression(featuresCol="features", labelCol="infected", maxIter=100, regParam=0.1, elasticNetParam=0.8)

# 2. Fit model with training data
lr_model = lr_classifier.fit(train_df)

# 3. Predict using test data
predictions = lr_model.transform(test_df)

# 4. Evaluate Model

# a. Area Under ROC (AUC)
binary_evaluator = BinaryClassificationEvaluator(labelCol="infected", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
roc_auc = binary_evaluator.evaluate(predictions)
print(f"Area Under ROC (AUC): {roc_auc:.2f}")

# b. Confusion Matrix
conf_matrix = predictions.groupBy("infected", "prediction").count().toPandas()
conf_matrix_pivot = conf_matrix.pivot(index="infected", columns="prediction", values="count").fillna(0).astype(int)

# Visualize Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_pivot, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Negative", "Positive"],
            yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# c. Classification Report
def extract_labels_and_predictions(predictions):
    labels_and_preds = predictions.select("infected", "prediction").rdd.map(lambda row: (row["infected"], row["prediction"])).collect()
    y_true, y_pred = zip(*labels_and_preds)
    return y_true, y_pred

y_true, y_pred = extract_labels_and_predictions(predictions)
report = classification_report(y_true, y_pred, target_names=["Negative", "Positive"])
print("\nClassification Report:")
print(report)

# d. ROC Curve
def plot_roc_curve(predictions):
    # Extract probabilities and labels
    probabilities = predictions.select("probability").rdd.map(lambda row: float(row["probability"][1])).collect()
    labels = predictions.select("infected").rdd.map(lambda row: row["infected"]).collect()

    # Calculate ROC curve
    fpr, tpr, _ = roc_curve(labels, probabilities)

    # Plot ROC curve
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='red', linestyle='--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.show()

plot_roc_curve(predictions)

"""# SVM"""

# Import libraries
from pyspark.ml.classification import LinearSVC
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.sql import SparkSession
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, roc_curve

# Initialize Spark session
spark = SparkSession.builder.appName("SVMClassifier").getOrCreate()

# Assuming train_df and test_df are already created and preprocessed as PySpark DataFrames

# 1. Initialize Support Vector Machine (SVM) Classifier using LinearSVC
svm_classifier = LinearSVC(featuresCol="features", labelCol="infected", maxIter=100, regParam=0.1, tol=1e-6)

# 2. Fit model with training data
svm_model = svm_classifier.fit(train_df)

# 3. Predict using test data
predictions = svm_model.transform(test_df)

# 4. Evaluate Model

# a. Area Under ROC (AUC)
evaluator_auc = BinaryClassificationEvaluator(labelCol="infected", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
roc_auc = evaluator_auc.evaluate(predictions)
print(f"Area Under ROC (AUC): {roc_auc:.2f}")

# b. Confusion Matrix
conf_matrix = predictions.groupBy("infected", "prediction").count().toPandas()
conf_matrix_pivot = conf_matrix.pivot(index="infected", columns="prediction", values="count").fillna(0).astype(int)

# Visualize Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_pivot, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Negative", "Positive"],
            yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# c. Classification Report
def extract_labels_and_predictions(predictions):
    labels_and_preds = predictions.select("infected", "prediction").rdd.map(lambda row: (row["infected"], row["prediction"])).collect()
    y_true, y_pred = zip(*labels_and_preds)
    return y_true, y_pred

y_true, y_pred = extract_labels_and_predictions(predictions)
report = classification_report(y_true, y_pred, target_names=["Negative", "Positive"])
print("\nClassification Report:")
print(report)

# d. ROC Curve
def plot_roc_curve(predictions):
    # Extract probabilities and labels
    raw_scores = predictions.select("rawPrediction").rdd.map(lambda row: float(row["rawPrediction"][1])).collect()
    labels = predictions.select("infected").rdd.map(lambda row: row["infected"]).collect()

    # Calculate ROC curve
    fpr, tpr, _ = roc_curve(labels, raw_scores)

    # Plot ROC curve
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='red', linestyle='--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.show()

plot_roc_curve(predictions)

"""# **HYPERPARAMETER TUNING**"""

# Import libraries
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml.feature import VectorAssembler
from pyspark.sql import SparkSession
import matplotlib.pyplot as plt
import seaborn as sns
from pyspark.sql.functions import col
from sklearn.metrics import classification_report, roc_curve

# Initialize Spark session
spark = SparkSession.builder.appName("HyperparameterTuning_RF").getOrCreate()

# 1. Initialize Random Forest Classifier
rf_classifier = RandomForestClassifier(featuresCol="features", labelCol="infected", seed=42)

# 2. Define Hyperparameter Grid
paramGrid = (ParamGridBuilder()
             .addGrid(rf_classifier.numTrees, [50, 100, 150])   # Number of trees
             .addGrid(rf_classifier.maxDepth, [10, 15, 20])    # Maximum depth of trees
             .addGrid(rf_classifier.maxBins, [32, 64])         # Maximum bins for splitting
             .build())

# 3. Define Evaluator
evaluator = BinaryClassificationEvaluator(labelCol="infected", rawPredictionCol="rawPrediction", metricName="areaUnderROC")

# 4. CrossValidator
crossval = CrossValidator(estimator=rf_classifier,
                          estimatorParamMaps=paramGrid,
                          evaluator=evaluator,
                          numFolds=5,  # Number of folds for cross-validation
                          parallelism=2)  # Number of parallel tasks

# 5. Fit CrossValidator to Training Data
cv_model = crossval.fit(train_df)

# 6. Retrieve Best Model and Hyperparameters
best_model = cv_model.bestModel

# Print Best Hyperparameters
print("Best Hyperparameters:")
print(f"  numTrees: {best_model.getNumTrees}")
print(f"  maxDepth: {best_model.getOrDefault('maxDepth')}")
print(f"  maxBins: {best_model.getOrDefault('maxBins')}")

# 7. Make Predictions on Test Data
predictions = best_model.transform(test_df)

# Evaluate the Best Model
auc = evaluator.evaluate(predictions)
print(f"Best Model Area Under ROC (AUC): {auc:.2f}")

# 8. Confusion Matrix
conf_matrix = predictions.groupBy("infected", "prediction").count().toPandas()
conf_matrix_pivot = conf_matrix.pivot(index="infected", columns="prediction", values="count").fillna(0).astype(int)

# Visualize Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_pivot, annot=True, fmt="d", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# 9. Extract Labels and Predictions for Classification Report
def extract_labels_and_predictions(predictions):
    labels_and_preds = predictions.select("infected", "prediction").rdd.map(lambda row: (row["infected"], row["prediction"])).collect()
    y_true, y_pred = zip(*labels_and_preds)
    return y_true, y_pred

y_true, y_pred = extract_labels_and_predictions(predictions)

# Classification Report
report = classification_report(y_true, y_pred, target_names=["Negative", "Positive"])
print("\nClassification Report:")
print(report)

# 10. ROC Curve
def plot_roc_curve(predictions):
    # Extract probabilities and labels
    probabilities = predictions.select("probability").rdd.map(lambda row: float(row["probability"][1])).collect()
    labels = predictions.select("infected").rdd.map(lambda row: row["infected"]).collect()

    # Calculate ROC curve
    fpr, tpr, _ = roc_curve(labels, probabilities)

    # Plot ROC curve
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.2f})')
    plt.plot([0, 1], [0, 1], color='red', linestyle='--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.show()

plot_roc_curve(predictions)

# Import libraries
from pyspark.ml.classification import GBTClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.sql import SparkSession
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, roc_curve

# Initialize Spark session
spark = SparkSession.builder.appName("GBT_Hyperparameter_Tuning").getOrCreate()

# Assuming train_df and test_df are already created and preprocessed as PySpark DataFrames

# Define Gradient Boosting Classifier (GBT)
gbt_classifier = GBTClassifier(featuresCol="features", labelCol="infected", seed=42)

# Define the hyperparameter grid
paramGrid = (ParamGridBuilder()
             .addGrid(gbt_classifier.maxDepth, [5, 10, 15])        # Maximum depth of trees
             .addGrid(gbt_classifier.maxIter, [50, 100, 150])      # Number of iterations (trees)
             .addGrid(gbt_classifier.stepSize, [0.1, 0.2])         # Learning rate (step size)
             .build())

# Define the evaluator
evaluator = BinaryClassificationEvaluator(
    labelCol="infected",
    rawPredictionCol="rawPrediction",
    metricName="areaUnderROC"
)

# Initialize CrossValidator
crossval = CrossValidator(
    estimator=gbt_classifier,
    estimatorParamMaps=paramGrid,
    evaluator=evaluator,
    numFolds=5,  # Number of folds for cross-validation
    parallelism=2  # Number of threads to use for parallelism
)

# Fit the CrossValidator to find the best model
cv_model = crossval.fit(train_df)

# Retrieve the best model
best_model = cv_model.bestModel

# Evaluate the best model on the test dataset
predictions = best_model.transform(test_df)
roc_auc = evaluator.evaluate(predictions)

# Print the best hyperparameters and evaluation metrics
print("Best Model Hyperparameters:")
print(f"  maxDepth: {best_model.getOrDefault('maxDepth')}")
print(f"  maxIter: {best_model.getOrDefault('maxIter')}")
print(f"  stepSize: {best_model.getOrDefault('stepSize')}")
print(f"Best Model Area Under ROC (AUC): {roc_auc:.2f}")

# Confusion Matrix
conf_matrix = predictions.groupBy("infected", "prediction").count().toPandas()
conf_matrix_pivot = conf_matrix.pivot(index="infected", columns="prediction", values="count").fillna(0).astype(int)

# Visualize Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_pivot, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Negative", "Positive"],
            yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# Classification Report
def extract_labels_and_predictions(predictions):
    labels_and_preds = predictions.select("infected", "prediction").rdd.map(lambda row: (row["infected"], row["prediction"])).collect()
    y_true, y_pred = zip(*labels_and_preds)
    return y_true, y_pred

y_true, y_pred = extract_labels_and_predictions(predictions)
report = classification_report(y_true, y_pred, target_names=["Negative", "Positive"])
print("\nClassification Report:")
print(report)

# ROC Curve
def plot_roc_curve(predictions):
    # Extract probabilities and labels
    probabilities = predictions.select("probability").rdd.map(lambda row: float(row["probability"][1])).collect()
    labels = predictions.select("infected").rdd.map(lambda row: row["infected"]).collect()

    # Calculate ROC curve
    fpr, tpr, _ = roc_curve(labels, probabilities)

    # Plot ROC curve
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='red', linestyle='--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend(loc="lower right")
    plt.show()

plot_roc_curve(predictions)